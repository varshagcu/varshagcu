{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Build the ensemble classifer\n",
    "\n",
    "Ensemble models combine the decisions from multiple models, and thus improving its performance. \n",
    "\n",
    "Therefore, first we have to understand the basic ensemble techniques. They are,\n",
    "1) Max Voting\n",
    "2)Averaging\n",
    "3)Weighed Average\n",
    "4)Bagging\n",
    "5)Boosting\n",
    "\n",
    "The advantages of bagging and boosting techniques are, there are already many algorithms based on them and \n",
    "satisfying the project needs to have an ensemble model just by calling their library. \n",
    "\n",
    "Eg of such algorithms are Ada Boost, XGB, Random Forest and so on.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e3099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#importing machine learning models for prediction\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d13432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data is used to create the model\n",
    "# PAMAP2 dataset was not loading because of the size it seems\n",
    "df = pd.read_csv('train_data.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting target data from the dataframe\n",
    "target = df[\"target\"]\n",
    " \n",
    "# getting train data from the dataframe\n",
    "train = df.drop(\"target\")\n",
    " \n",
    "# Splitting between train data into training and validation dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train, target, test_size=0.20)\n",
    " \n",
    "# initializing all the model objects with default parameters\n",
    "model_1 = LinearRegression()\n",
    "model_2 = xgb.XGBRegressor()\n",
    "model_3 = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4287c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training all the model on the training dataset\n",
    "model_1.fit(X_train, y_target)\n",
    "model_2.fit(X_train, y_target)\n",
    "model_3.fit(X_train, y_target)\n",
    " \n",
    "# predicting the output on the validation dataset\n",
    "pred_1 = model_1.predict(X_test)\n",
    "pred_2 = model_2.predict(X_test)\n",
    "pred_3 = model_3.predict(X_test)\n",
    " \n",
    "# final prediction after averaging on the prediction of all 3 models\n",
    "pred_final = (pred_1+pred_2+pred_3)/3.0\n",
    " \n",
    "# printing the root mean squared error between real value and predicted value\n",
    "print(mean_squared_error(y_test, pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04eacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame object into NumPy array otherwise you will not be able to impute\n",
    "values = df.values\n",
    "\n",
    "# Now impute it\n",
    "imputer = Imputer()\n",
    "imputedData = imputer.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4121aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another Model\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting target data from the dataframe\n",
    "x = df[\"AT_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting train data from the dataframe\n",
    "y = df[\"GC_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a277fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657fc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eeab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b01a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models.list()\n",
    "models.append('knn', KNeighbors(n_neighbors =3))\n",
    "models.append('lr', LogisticRegression(multiclass))\n",
    "models.append('nb', GaussianNB())\n",
    "\n",
    "ensemble = VotingClassifer(estimator=models, voting=\"hard\")\n",
    "\n",
    "#Now the ensemble model is ready, the only pending thing is\n",
    "#predicting the model\n",
    "\n",
    "predictions = clf.predict(X_validation)\n",
    "print(accuracy_score (y_validation, predictions))\n",
    "\n",
    "#That's it. The above where step by step refrence on how to \n",
    "#build an ensemble classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
